{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f3228c-3d05-48e1-827a-505629a1bfcc",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ce5eb9-9799-494a-81d6-e75aa470047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ac\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords for text cleaning\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fca1c-36cf-47be-8b11-9b05309d2c98",
   "metadata": {},
   "source": [
    "# Load and Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad45f99-a148-4697-bc02-49337fb59a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  intensity\n",
      "0  Wants to know how the hell I can remember word...  happiness\n",
      "1  Love is a long sweet dream & marriage is an al...  happiness\n",
      "2  The world could be amazing when you are slight...  happiness\n",
      "3  My secret talent is getting tired without doin...  happiness\n",
      "4  Khatarnaak Whatsapp Status Ever‚Ä¶ Can\\‚Äôt talk, ...  happiness\n",
      "                                             content  intensity\n",
      "0  Sometimes I‚Äôm not angry, I‚Äôm hurt and there‚Äôs ...  angriness\n",
      "1                     Not available for busy people‚ò∫  angriness\n",
      "2  I do not exist to impress the world. I exist t...  angriness\n",
      "3  Everything is getting expensive except some pe...  angriness\n",
      "4       My phone screen is brighter than my future üôÅ  angriness\n",
      "                                             content intensity\n",
      "0  Never hurt people who love you a lot, because ...   sadness\n",
      "1  Don‚Äôt expect me to tell you what you did wrong...   sadness\n",
      "2  I preferred walking away than fighting for you...   sadness\n",
      "3  Moving forward in life isn‚Äôt the hard part, it...   sadness\n",
      "4  Never cry for anyone in your life, because tho...   sadness\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "happiness = pd.read_csv(\"happiness.csv\")\n",
    "angriness = pd.read_csv(\"angriness.csv\")\n",
    "sadness = pd.read_csv(\"sadness.csv\")\n",
    "\n",
    "# Display datasets\n",
    "print(happiness.head())\n",
    "print(angriness.head())\n",
    "print(sadness.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a9f58-eaa8-43f3-b0d8-b43a5e989634",
   "metadata": {},
   "source": [
    "## Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70170943-8ca9-4ee3-b6ed-5b12c9b28926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  intensity\n",
      "0  Wants to know how the hell I can remember word...  happiness\n",
      "1  Love is a long sweet dream & marriage is an al...  happiness\n",
      "2  The world could be amazing when you are slight...  happiness\n",
      "3  My secret talent is getting tired without doin...  happiness\n",
      "4  Khatarnaak Whatsapp Status Ever‚Ä¶ Can\\‚Äôt talk, ...  happiness\n"
     ]
    }
   ],
   "source": [
    "# Combine the datasets into one DataFrame\n",
    "data = pd.concat([happiness, angriness, sadness], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f4076-5b68-41d5-9508-60a7d57c7178",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1657e9-145e-4f61-a3fe-56105d4d7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text by making it lowercase and removing special characters\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Make all letters lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove everything except letters and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stop words\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'content' column\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['content_clean'] = data['content'].apply(clean_text)\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    data['content_clean'], data['intensity'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a65ced-abd0-4240-a199-f5ff9450e029",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69dee007-a11d-400c-84d3-9a9b025a7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the cleaned text data into numerical features using unigrams, bigrams, and trigrams\n",
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)  # Fit on training data\n",
    "X_test_tfidf = tfidf.transform(X_test_text)  # Transform the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7c71f-6877-4328-a37a-3bb1e77a1544",
   "metadata": {},
   "source": [
    "# Model Selection and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7bb8b5-fb53-4264-b567-d13ea00b5d10",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73539409-f64b-4fd7-b4b1-647e8da24e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.7916666666666666\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   angriness       0.85      0.81      0.83       133\n",
      "   happiness       0.70      0.88      0.78       156\n",
      "     sadness       0.92      0.65      0.76       119\n",
      "\n",
      "    accuracy                           0.79       408\n",
      "   macro avg       0.82      0.78      0.79       408\n",
      "weighted avg       0.81      0.79      0.79       408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Model Training\n",
    "svm_model = SVC(C=1, kernel='rbf')  # 'C' is the regularization parameter\n",
    "svm_model.fit(X_train_tfidf, y_train)  # Train the model on the training data\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_svm}\")\n",
    "print(f\"SVM Classification Report:\\n{report_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59cabde-7314-4037-9b34-6d7fe7b6bcf7",
   "metadata": {},
   "source": [
    "####  Grid Search for SVM Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13895838-5dd0-426e-8862-2d4b24700ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best SVM parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "grid_svm = GridSearchCV(SVC(), param_grid_svm, refit=True, verbose=1)\n",
    "grid_svm.fit(X_train_tfidf, y_train)\n",
    "print(f\"Best SVM parameters: {grid_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad29010-9676-4caa-9688-4bce4ca1d8dc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1257eb-b857-4a2d-9656-676114f80329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model Training\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "y_pred_log = log_reg.predict(X_test_tfidf)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(f\"Logistic Regression Test Accuracy: {accuracy_log}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7a0df-4673-45b2-ad1f-9f6d297f9ddc",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0873ddd8-f298-4dc6-a600-2dc2141899fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test Accuracy: 0.6936274509803921\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model Training\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "print(f\"Naive Bayes Test Accuracy: {accuracy_nb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21eaa1b-f36d-466f-a855-fe4fdd2f830b",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e40a515e-7506-4668-97c6-b218b635b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.7867647058823529\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model Training\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aab728-9ac5-46ff-9872-1661598f62a5",
   "metadata": {},
   "source": [
    "####  Grid Search for Random Forest Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db92d107-4cd3-4829-a157-c56406576b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest parameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3)\n",
    "grid_rf.fit(X_train_tfidf, y_train)\n",
    "print(f\"Best Random Forest parameters: {grid_rf.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b769be-288b-44a7-bb8b-113075426a49",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "311a72ce-1c34-4b46-86a9-a9b7d7d7edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Test Accuracy: 0.7230392156862745\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Model Training\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_tfidf)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"Gradient Boosting Test Accuracy: {accuracy_gb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ecfaac-0bbe-4b15-9f95-c0707a652efb",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "300d60f3-86f7-4308-96f7-77d86b00b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Test Accuracy: 0.8063725490196079\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier Training\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm_model), \n",
    "    ('rf', rf_model), \n",
    "    ('gb', gb_model)\n",
    "], voting='hard')\n",
    "voting_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_voting = voting_clf.predict(X_test_tfidf)\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "\n",
    "print(f\"Voting Classifier Test Accuracy: {accuracy_voting}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fde27-7d2b-4b55-9fce-4ac819032a8d",
   "metadata": {},
   "source": [
    "# Top two Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68bd8c51-9cc5-4a2c-9506-eac520f19df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier model saved as 'voting_classifier_model.pkl'\n",
      "SVM model saved as 'svm_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the Voting Classifier model\n",
    "joblib.dump(voting_clf, 'models/voting_classifier_model.pkl')\n",
    "\n",
    "# Save the SVM model\n",
    "joblib.dump(svm_model, 'models/svm_model.pkl')\n",
    "\n",
    "# Verify the files are saved\n",
    "print(\"Voting Classifier model saved as 'voting_classifier_model.pkl'\")\n",
    "print(\"SVM model saved as 'svm_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f152444-285e-4210-a6c3-af33a277d564",
   "metadata": {},
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df727793-b8ad-4afe-84f6-63b719d18d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Intensity (SVM): happiness\n",
      "Predicted Intensity (Voting Classifier): happiness\n"
     ]
    }
   ],
   "source": [
    "# Input text to test the model\n",
    "test_text = [\"I am feeling extremely happy today!\"]\n",
    "\n",
    "# Preprocess the input using the loaded TF-IDF vectorizer\n",
    "test_text_tfidf = tfidf_vectorizer_loaded.transform(test_text)\n",
    "\n",
    "# Make predictions using the loaded models\n",
    "prediction_svm = svm_model_loaded.predict(test_text_tfidf)\n",
    "\n",
    "prediction_voting = voting_clf_loaded.predict(test_text_tfidf)\n",
    "\n",
    "# Print the predicted classes\n",
    "print(f\"Predicted Intensity (SVM): {prediction_svm[0]}\")\n",
    "\n",
    "print(f\"Predicted Intensity (Voting Classifier): {prediction_voting[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e526e4-88dd-4e6a-bd58-793b1198ecd0",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c17c3-648b-473a-a8b8-0648fd07515a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
